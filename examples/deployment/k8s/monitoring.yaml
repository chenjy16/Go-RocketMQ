# Go-RocketMQ 监控配置

---
# ServiceMonitor for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: rocketmq-servicemonitor
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: go-rocketmq
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http
      scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
      - rocketmq

---
# PrometheusRule for alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: rocketmq-alerts
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
spec:
  groups:
    - name: rocketmq.rules
      rules:
        # NameServer告警
        - alert: RocketMQNameServerDown
          expr: up{job="rocketmq-nameserver"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "RocketMQ NameServer is down"
            description: "RocketMQ NameServer {{ $labels.instance }} has been down for more than 1 minute."
        
        # Broker告警
        - alert: RocketMQBrokerDown
          expr: up{job="rocketmq-broker"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "RocketMQ Broker is down"
            description: "RocketMQ Broker {{ $labels.instance }} has been down for more than 1 minute."
        
        # 消息堆积告警
        - alert: RocketMQMessageAccumulation
          expr: rocketmq_consumer_lag > 10000
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "RocketMQ message accumulation is high"
            description: "Consumer group {{ $labels.consumer_group }} has {{ $value }} messages accumulated."
        
        # 磁盘使用率告警
        - alert: RocketMQDiskUsageHigh
          expr: (rocketmq_disk_used_bytes / rocketmq_disk_total_bytes) * 100 > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "RocketMQ disk usage is high"
            description: "Broker {{ $labels.instance }} disk usage is {{ $value }}%."
        
        # 内存使用率告警
        - alert: RocketMQMemoryUsageHigh
          expr: (rocketmq_memory_used_bytes / rocketmq_memory_total_bytes) * 100 > 85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "RocketMQ memory usage is high"
            description: "Instance {{ $labels.instance }} memory usage is {{ $value }}%."
        
        # 生产者发送失败率告警
        - alert: RocketMQProducerSendFailureRateHigh
          expr: (rate(rocketmq_producer_send_failed_total[5m]) / rate(rocketmq_producer_send_total[5m])) * 100 > 5
          for: 3m
          labels:
            severity: warning
          annotations:
            summary: "RocketMQ producer send failure rate is high"
            description: "Producer {{ $labels.producer_group }} send failure rate is {{ $value }}%."
        
        # 消费者消费失败率告警
        - alert: RocketMQConsumerConsumeFailureRateHigh
          expr: (rate(rocketmq_consumer_consume_failed_total[5m]) / rate(rocketmq_consumer_consume_total[5m])) * 100 > 5
          for: 3m
          labels:
            severity: warning
          annotations:
            summary: "RocketMQ consumer consume failure rate is high"
            description: "Consumer group {{ $labels.consumer_group }} consume failure rate is {{ $value }}%."

---
# Grafana Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: rocketmq-dashboard
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
    grafana_dashboard: "1"
data:
  rocketmq-dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Go-RocketMQ Dashboard",
        "tags": ["rocketmq", "messaging"],
        "style": "dark",
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "NameServer Status",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=\"rocketmq-nameserver\"}",
                "legendFormat": "{{ instance }}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Broker Status",
            "type": "stat",
            "targets": [
              {
                "expr": "up{job=\"rocketmq-broker\"}",
                "legendFormat": "{{ instance }}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            },
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Message Send Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(rocketmq_producer_send_total[5m])",
                "legendFormat": "{{ producer_group }}"
              }
            ],
            "yAxes": [
              {"label": "Messages/sec", "min": 0}
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Message Consume Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(rocketmq_consumer_consume_total[5m])",
                "legendFormat": "{{ consumer_group }}"
              }
            ],
            "yAxes": [
              {"label": "Messages/sec", "min": 0}
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
          },
          {
            "id": 5,
            "title": "Consumer Lag",
            "type": "graph",
            "targets": [
              {
                "expr": "rocketmq_consumer_lag",
                "legendFormat": "{{ consumer_group }} - {{ topic }}"
              }
            ],
            "yAxes": [
              {"label": "Messages", "min": 0}
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24}
          },
          {
            "id": 6,
            "title": "Disk Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "(rocketmq_disk_used_bytes / rocketmq_disk_total_bytes) * 100",
                "legendFormat": "{{ instance }}"
              }
            ],
            "yAxes": [
              {"label": "Percentage", "min": 0, "max": 100}
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 32}
          },
          {
            "id": 7,
            "title": "Memory Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "(rocketmq_memory_used_bytes / rocketmq_memory_total_bytes) * 100",
                "legendFormat": "{{ instance }}"
              }
            ],
            "yAxes": [
              {"label": "Percentage", "min": 0, "max": 100}
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 32}
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }

---
# Prometheus配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
    
    scrape_configs:
      - job_name: 'rocketmq-nameserver'
        static_configs:
          - targets: ['nameserver-service:8080']
        metrics_path: /metrics
        scrape_interval: 30s
      
      - job_name: 'rocketmq-broker'
        static_configs:
          - targets: ['broker-master-service:8080', 'broker-slave-service:8080']
        metrics_path: /metrics
        scrape_interval: 30s
      
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - rocketmq
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

---
# Alertmanager配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@example.com'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
    
    receivers:
      - name: 'web.hook'
        webhook_configs:
          - url: 'http://webhook-service:5001/'
            send_resolved: true
      
      - name: 'email'
        email_configs:
          - to: 'admin@example.com'
            subject: 'RocketMQ Alert: {{ .GroupLabels.alertname }}'
            body: |
              {{ range .Alerts }}
              Alert: {{ .Annotations.summary }}
              Description: {{ .Annotations.description }}
              {{ end }}
    
    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'dev', 'instance']

---
# Jaeger配置（分布式追踪）
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-config
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
data:
  jaeger.yml: |
    collector:
      zipkin:
        host-port: ":9411"
    
    storage:
      type: elasticsearch
      elasticsearch:
        server-urls: http://elasticsearch:9200
        index-prefix: jaeger
    
    query:
      base-path: /jaeger
    
    agent:
      jaeger:
        thrift-compact:
          port: 6831
        thrift-binary:
          port: 6832
        grpc:
          port: 14250

---
# 日志收集配置（Fluent Bit）
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: rocketmq
  labels:
    app.kubernetes.io/name: go-rocketmq
    app.kubernetes.io/part-of: go-rocketmq
    app.kubernetes.io/component: monitoring
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020
    
    [INPUT]
        Name              tail
        Path              /var/log/rocketmq/*.log
        Parser            rocketmq
        Tag               rocketmq.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB
    
    [FILTER]
        Name                kubernetes
        Match               rocketmq.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix     rocketmq.var.log.rocketmq.
        Merge_Log           On
        Keep_Log            Off
    
    [OUTPUT]
        Name  es
        Match *
        Host  elasticsearch
        Port  9200
        Index rocketmq-logs
        Type  _doc
  
  parsers.conf: |
    [PARSER]
        Name        rocketmq
        Format      regex
        Regex       ^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) (?<level>\w+) (?<logger>\S+) - (?<message>.*)
        Time_Key    time
        Time_Format %Y-%m-%d %H:%M:%S,%L